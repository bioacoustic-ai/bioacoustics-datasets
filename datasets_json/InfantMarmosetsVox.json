{
  "additional description": "Recorded on 5 pairs of marmosets twins. Thw twins were separated and recorded individually",
  "annotations type": "The onset and offset of call, call type, and individual",
  "capture device": "Audio-Technica AT2031 microphone",
  "cite_as": null,
  "continent": NaN,
  "country code": NaN,
  "creators": [
    "Sarkar, Eklavya",
    "Magimai Doss, Mathew"
  ],
  "date_published": "2023-11-15T07:14:51.400757+00:00",
  "description": "**Description**\n\nInfantMarmosetsVox is a dataset for multi-class call-type and caller\nidentification. It contains audio recordings of different individual marmosets\nand their call-types. The dataset contains a total of 350 files of precisely\nlabelled 10-minute audio recordings across all caller classes. The audio was\nrecorded from five pairs of infant marmoset twins, each recorded individually\nin two separate sound-proofed recording rooms at a sampling rate of 44.1 kHz.\nThe start and end time, call-type, and marmoset identity of each vocalization\nare provided, labeled by an experienced researcher.\n\n\n\n**References**\n\nThis dataset was collected and partially used for the paper \"Automatic\ndetection and classification of marmoset vocalizations using deep and\nrecurrent neural networks\" by Zhang et al.\n\nIt is also used for the experiments in the paper \"Can Self-Supervised Neural\nRepresentations Pre-Trained on Human Speech distinguish Animal Callers?\" by E.\nSarkar and M. Magimai-Doss.\n\nThe source code of a PyTorch DataLoader reading this data is available at\n<https://github.com/idiap/ssl-caller-detection>.\n\n\n\n**Citation**\n\nAny publication (eg. conference paper, journal article, technical report, book\nchapter, etc) resulting from the usage of InfantsMarmosetVox must cite the\nfollowing publication:\n\nSarkar, E., Magimai.-Doss, M. (2023) Can Self-Supervised Neural\nRepresentations Pre-Trained on Human Speech distinguish Animal Callers? Proc.\nINTERSPEECH 2023, 1189-1193, doi: 10.21437/Interspeech.2023-1968\n\nBibtex:\n\n@inproceedings{sarkar23_interspeech,  \n  author={Eklavya Sarkar and Mathew Magimai.-Doss},  \n  title={{Can Self-Supervised Neural Representations Pre-Trained on Human\nSpeech distinguish Animal Callers?}},  \n  year=2023,  \n  booktitle={Proc. INTERSPEECH 2023},  \n  pages={1189--1193},  \n  doi={10.21437/Interspeech.2023-1968}  \n}\n\n",
  "labelling level": NaN,
  "license": "cc-by-4.0",
  "life stage": NaN,
  "locality": "Two separate sound-proofed recording rooms",
  "min and max recording duration (sec)": NaN,
  "name": "InfantMarmosetsVox",
  "num. annotations": 169318,
  "num. audio files": 350,
  "num. classes": "10 calls\n10 individuals",
  "num. species": NaN,
  "paper_link": "https://arxiv.org/pdf/2305.14035",
  "physical setting": NaN,
  "provider": "University of Science and Technology of China",
  "recording period": "every few days lasting about three months after marmosets' birth",
  "recording type": "Continuous",
  "sample rate (khz)": NaN,
  "size (gb)": 21.2,
  "species": NaN,
  "taxonomic class": "Primates",
  "total duration (hours)": 58.33333333,
  "url": "https://zenodo.org/records/10130104",
  "version": 1
}